{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610dbbd-84b7-4f25-82e7-43bc66ca642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202e7882-52df-49c1-b5eb-bb09e1a1c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbddcaa4-37ff-4408-85b9-602bbe577a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e2e0db-8f9c-4b36-9ce7-a65e76cffd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe holistic and drawing modules\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize holistic model with confidence thresholds\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "        \n",
    "        # Recolor the image from BGR (OpenCV default) to RGB (for MediaPipe)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Improves performance for detection\n",
    "        \n",
    "        # Perform the holistic model detection\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Set the image to writeable to draw on it\n",
    "        image.flags.writeable = True  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert it back to BGR for rendering with OpenCV\n",
    "        \n",
    "        # 1. Draw face landmarks if available\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.face_landmarks, \n",
    "                mp_face_mesh.FACEMESH_CONTOURS,  # Face mesh connections for drawing face landmarks\n",
    "                mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "            )\n",
    "        \n",
    "        # 2. Draw right hand landmarks if available\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.right_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 3. Draw left hand landmarks if available\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.left_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 4. Draw pose landmarks if available\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,  # Correct pose connections\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Holistic Webcam Feed', image)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e463ed3-3b76-47e8-9ab4-631353e375ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pose_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26d6aa0-f40f-4b5f-9fe4-75848bf1c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1263c8-35c6-48a6-a655-bfd4cdcdade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3144da5d-68e7-41a7-b3c1-e692a5ffea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bb34b-71cc-4223-94d1-a7dd18092325",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06cf6db9-3c85-4987-aa6e-5f0e0c510bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b55126e-2659-45a7-a78e-4843f8f26768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d18b97-7538-45d7-9dc8-dd7c4c32184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe holistic and drawing modules\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize holistic model with confidence thresholds\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "        \n",
    "        # Recolor the image from BGR (OpenCV default) to RGB (for MediaPipe)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Improves performance for detection\n",
    "        \n",
    "        # Perform the holistic model detection\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Set the image to writeable to draw on it\n",
    "        image.flags.writeable = True  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert it back to BGR for rendering with OpenCV\n",
    "        \n",
    "        # 1. Draw face landmarks if available\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.face_landmarks, \n",
    "                mp_face_mesh.FACEMESH_CONTOURS,  # Face mesh connections for drawing face landmarks\n",
    "                mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "            )\n",
    "        \n",
    "        # 2. Draw right hand landmarks if available\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.right_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 3. Draw left hand landmarks if available\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.left_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 4. Draw pose landmarks if available\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,  # Correct pose connections\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass    \n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Holistic Webcam Feed', image)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70bb3760-7cd9-46bc-99d3-99e9248969f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ce3e67-60d2-480c-9d97-968ea1cf2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290e01c-d671-4c2f-bedb-4578c1867312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e0233-0317-4748-b37c-afd717aabfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2917dfc-740f-4efa-99ff-3ff1956ec412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='Happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a28bd-5de4-4d59-a69f-58248e55e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='Sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993181fa-6e6d-403b-8c92-bf853b4e57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d73130-f519-428f-af6b-86c0f8981779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64d1f1-6151-40ea-918c-26d43acc0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc56ea9-e396-42db-b380-e9571a49a1e7",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9576baf-0dfa-4061-8e60-efcec1397716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4cde7db4-077c-40e6-b1f6-c2b0eec8b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3993b8-04cc-4fd8-bb1a-1dfdba6b86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c05633-abdf-481a-b8b6-e960b56282ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939a340-5f67-49a6-a929-86130e5fe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56004f1-8ee9-4965-bd01-e2a440133072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21112f-d472-4bba-b954-69c3789c6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b86f1f-de10-4f52-9196-ccb8b83d8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f0e0a-e2a0-4934-8413-2f4e27dec575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5744279-05e2-4380-80e7-623f81bfc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a678321f-5afa-4eff-9388-ab6c8deaa624",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df3ad0-e46b-48f6-a05b-71888588538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b18d6e-762c-4cc5-9383-80bc16e21851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe holistic and drawing modules\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize holistic model with confidence thresholds\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "        \n",
    "        # Recolor the image from BGR (OpenCV default) to RGB (for MediaPipe)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Improves performance for detection\n",
    "        \n",
    "        # Perform the holistic model detection\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Set the image to writeable to draw on it\n",
    "        image.flags.writeable = True  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert it back to BGR for rendering with OpenCV\n",
    "        \n",
    "        # 1. Draw face landmarks if available\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.face_landmarks, \n",
    "                mp_face_mesh.FACEMESH_CONTOURS,  # Face mesh connections for drawing face landmarks\n",
    "                mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "            )\n",
    "        \n",
    "        # 2. Draw right hand landmarks if available\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.right_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 3. Draw left hand landmarks if available\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.left_hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,  # Correct hand connections\n",
    "                mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        \n",
    "        # 4. Draw pose landmarks if available\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,  # Correct pose connections\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass    \n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Holistic Webcam Feed', image)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868781a-3a58-4b1c-b3c3-6c5c5d1a7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2df4d-6cb0-4633-baeb-1a71b91b116f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "panel-cell-order": [
   "8299815b-fd2f-41d9-8a04-08ca7e3f1463",
   "4bff8113-019e-4dda-9ae2-e446658c7039"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
